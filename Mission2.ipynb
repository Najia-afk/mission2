{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c0d9927-7ee4-44a0-8e1e-e582121efd41",
   "metadata": {
    "panel-layout": {
     "height": 93.5804,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Import des Dataframes et premier niveau d'analyse\n",
    "\n",
    "Dans cette section, nous allons importer les datasets sous forme de dataframes et nous allons faire une analyse pas à pas de leur structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537600a9-d320-4272-876d-c1a462e44bb7",
   "metadata": {
    "panel-layout": {
     "height": 101.554,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Import de tous les datasets d'un répertoire sous forme de dataframes\n",
    "\n",
    "Ces fonctions localisent le répertoire racine du notebook Jupyter et importent tous les datasets du répertoire './Dataset'. Elles nomment les DataFrames en conséquence et, si tout se charge correctement, elles affichent les cinq premières lignes de chaque DataFrame chargé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "76e674d2-b71c-42c7-84a8-6b77cc2b78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Adjust display options to show all columns\n",
    "pd.set_option('display.max_columns', 5)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "# Relative path to the dataset directory\n",
    "dataset_directory = 'Dataset'\n",
    "\n",
    "# Get the current working directory (notebook's directory)\n",
    "notebook_directory = os.getcwd()\n",
    "\n",
    "# Construct full path to the dataset directory\n",
    "directory = os.path.join(notebook_directory, dataset_directory)\n",
    "\n",
    "# Check if the dataset directory exists\n",
    "if not os.path.exists(directory):\n",
    "    print(f\"Error: Directory '{directory}' does not exist.\")\n",
    "else:\n",
    "    # List all files in the dataset directory\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "\n",
    "    # Dictionary to store DataFrames\n",
    "    dfs = {}\n",
    "\n",
    "    # Function to display loaded DataFrames\n",
    "    def show_loaded_dfs(df_names=None):\n",
    "        \"\"\"\n",
    "        Displays the head of the loaded DataFrames.\n",
    "        \n",
    "        Parameters:\n",
    "        - df_names (list): Optional list of DataFrame names to display. If None, all DataFrames are displayed.\n",
    "        \"\"\"\n",
    "        print(\"Currently loaded DataFrames:\")\n",
    "        if df_names is None:\n",
    "            for name, df in dfs.items():\n",
    "                print(f\"DataFrame for file '{name}':\")\n",
    "                print(df.head())\n",
    "                print(\"\\n\")\n",
    "        else:\n",
    "            for name in df_names:\n",
    "                if name in dfs:\n",
    "                    print(f\"DataFrame for file '{name}':\")\n",
    "                    print(dfs[name].head())\n",
    "                    print(\"\\n\")\n",
    "                else:\n",
    "                    print(f\"DataFrame '{name}' not found in the loaded DataFrames.\\n\")\n",
    "\n",
    "    # Function to preprocess DataFrames by dropping empty columns\n",
    "    def preprocess_df(df):\n",
    "        # Drop columns that are entirely empty\n",
    "        return df.dropna(axis=1, how='all')\n",
    "\n",
    "    # Load each file into a DataFrame, preprocess, and create dynamic variables\n",
    "    for file in files:\n",
    "        file_name = os.path.splitext(file)[0]\n",
    "        file_path = os.path.join(directory, file)\n",
    "        df = pd.read_csv(file_path)  # Adjust if not CSV\n",
    "        df = preprocess_df(df)  # Preprocess the DataFrame\n",
    "        dfs[file_name] = df\n",
    "        globals()[file_name] = df  # Create a dynamic variable in the global namespace\n",
    "\n",
    "    \n",
    "\n",
    "    # Example usage\n",
    "    # show_loaded_dfs()  # To display all DataFrames\n",
    "    # show_loaded_dfs(['EdStatsCountry', 'EdStatsData'])  # To display specific DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50193f1b-e777-43fc-ac6d-2cde6de2243f",
   "metadata": {
    "panel-layout": {
     "height": 50.8214,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Resultat du script d'import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c4378a17-1da4-4d4e-86b9-969d71e8e3da",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently loaded DataFrames:\n",
      "DataFrame for file '.gitignore':\n",
      "             *\n",
      "0  !.gitignore\n",
      "\n",
      "\n",
      "DataFrame for file 'EdStatsCountry-Series':\n",
      "  CountryCode         SeriesCode                                        DESCRIPTION\n",
      "0         ABW        SP.POP.TOTL  Data sources : United Nations World Population...\n",
      "1         ABW        SP.POP.GROW  Data sources: United Nations World Population ...\n",
      "2         AFG        SP.POP.GROW  Data sources: United Nations World Population ...\n",
      "3         AFG  NY.GDP.PCAP.PP.CD                 Estimates are based on regression.\n",
      "4         AFG        SP.POP.TOTL  Data sources : United Nations World Population...\n",
      "\n",
      "\n",
      "DataFrame for file 'EdStatsCountry':\n",
      "  Country Code   Short Name  ... Latest trade data Latest water withdrawal data\n",
      "0          ABW        Aruba  ...            2012.0                          NaN\n",
      "1          AFG  Afghanistan  ...            2012.0                         2000\n",
      "2          AGO       Angola  ...               NaN                         2005\n",
      "3          ALB      Albania  ...            2012.0                         2006\n",
      "4          AND      Andorra  ...            2006.0                          NaN\n",
      "\n",
      "[5 rows x 31 columns]\n",
      "\n",
      "\n",
      "DataFrame for file 'EdStatsData':\n",
      "  Country Name Country Code  ... 2095 2100\n",
      "0   Arab World          ARB  ...  NaN  NaN\n",
      "1   Arab World          ARB  ...  NaN  NaN\n",
      "2   Arab World          ARB  ...  NaN  NaN\n",
      "3   Arab World          ARB  ...  NaN  NaN\n",
      "4   Arab World          ARB  ...  NaN  NaN\n",
      "\n",
      "[5 rows x 69 columns]\n",
      "\n",
      "\n",
      "DataFrame for file 'EdStatsFootNote':\n",
      "  CountryCode      SeriesCode    Year          DESCRIPTION\n",
      "0         ABW  SE.PRE.ENRL.FE  YR2001  Country estimation.\n",
      "1         ABW  SE.TER.TCHR.FE  YR2005  Country estimation.\n",
      "2         ABW  SE.PRE.TCHR.FE  YR2000  Country estimation.\n",
      "3         ABW  SE.SEC.ENRL.GC  YR2004  Country estimation.\n",
      "4         ABW     SE.PRE.TCHR  YR2006  Country estimation.\n",
      "\n",
      "\n",
      "DataFrame for file 'EdStatsSeries':\n",
      "           Series Code       Topic  ... Development relevance Related source links\n",
      "0  BAR.NOED.1519.FE.ZS  Attainment  ...                   NaN                  NaN\n",
      "1     BAR.NOED.1519.ZS  Attainment  ...                   NaN                  NaN\n",
      "2  BAR.NOED.15UP.FE.ZS  Attainment  ...                   NaN                  NaN\n",
      "3     BAR.NOED.15UP.ZS  Attainment  ...                   NaN                  NaN\n",
      "4  BAR.NOED.2024.FE.ZS  Attainment  ...                   NaN                  NaN\n",
      "\n",
      "[5 rows x 15 columns]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show loaded DataFrames\n",
    "show_loaded_dfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e873ebfe-0ba5-4287-a417-e3fdffad1ca1",
   "metadata": {
    "panel-layout": {
     "height": 101.554,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Analyse des Colonnes\n",
    "\n",
    "Nous allons analyser les colonnes de chaque DataFrame pour déterminer leur type, leur taux de remplissage, la présence de valeurs nulles, les faux \"null\" et déterminer des jointures possibles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "208d0847-46a4-4b22-8bfe-b550747b7f1a",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [],
   "source": [
    "# Adjust display options to show all columns\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "def analyze_column(col):\n",
    "    col_data = col.dropna()\n",
    "    col_dtypes = col.dtypes\n",
    "    \n",
    "    if col_data.empty:\n",
    "        col_type = 'NaN'\n",
    "        fill_percentage = 0.0\n",
    "        nan_percentage = 100.0\n",
    "        bad_null_percentage = 0.0\n",
    "    else:\n",
    "        type_counts = col_data.apply(lambda x: type(x).__name__).value_counts(normalize=True) * 100\n",
    "        if len(type_counts) == 1:\n",
    "            if type_counts.index[0] != 'NaN':\n",
    "                max_length = col_data.apply(lambda x: len(str(x))).max()\n",
    "                col_type = f\"{type_counts.index[0]}({max_length})\"\n",
    "            else:\n",
    "                col_type = type_counts.index[0]\n",
    "        else:\n",
    "            # If multiple types are present, compute errorType with percentages\n",
    "            error_type_details = ', '.join([f\"{t}: {p:.2f}%\" for t, p in type_counts.items()])\n",
    "            col_type = f\"errorType({error_type_details})\"\n",
    "        \n",
    "        fill_percentage = col_data.size / col.size * 100\n",
    "        nan_percentage = col.isna().sum() / col.size * 100\n",
    "        \n",
    "        # Check for other forms of null values\n",
    "        bad_null_count = col.isin(['', 'None', 'NULL', 'null']).sum()\n",
    "        bad_null_percentage = bad_null_count / col.size * 100\n",
    "\n",
    "    return {\n",
    "        'Column Name': col.name,\n",
    "        'Dtype': col_dtypes,\n",
    "        'Type': col_type,\n",
    "        'Fill Percentage': fill_percentage,\n",
    "        'NaN Percentage': nan_percentage,\n",
    "        'Bad Null Percentage': bad_null_percentage\n",
    "    }\n",
    "\n",
    "def analyze_dataframe(df):\n",
    "    columns_info = []\n",
    "    num_rows = len(df)\n",
    "    for col_name in df.columns:\n",
    "        col_info = analyze_column(df[col_name])\n",
    "        columns_info.append(col_info)\n",
    "    df_info = pd.DataFrame(columns_info)\n",
    "    return df_info, num_rows\n",
    "\n",
    "def create_metadata_dfs(dfs):\n",
    "    metadata_dfs = {}\n",
    "    for df_name, df in dfs.items():\n",
    "        metadata_df, num_rows = analyze_dataframe(df)\n",
    "        metadata_dfs[f'metadata_{df_name} {df.shape}'] = metadata_df\n",
    "    return metadata_dfs\n",
    "\n",
    "# Function to display metadata DataFrames\n",
    "def display_metadata_dfs(metadata_dfs):\n",
    "    for name, metadata_df in metadata_dfs.items():\n",
    "        print(f\"Metadata for {name}:\")\n",
    "        print(metadata_df)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Analyze DataFrames and create metadata DataFrames\n",
    "metadata_dfs = create_metadata_dfs(dfs)\n",
    "\n",
    "\n",
    "\n",
    "# Save the combined metadata DataFrame to a CSV file\n",
    "combined_metadata = pd.concat(metadata_dfs.values(), keys=metadata_dfs.keys()).reset_index(level=0).rename(columns={'level_0': 'DataFrame'})\n",
    "combined_metadata.to_csv('data/combined_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29f58f-bce7-4bd8-8bec-f4a3bc07b55a",
   "metadata": {
    "panel-layout": {
     "height": 50.8214,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Resultat du script d'analyse des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ae46763-fc45-4910-bf93-9d04dd20726b",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for metadata_.gitignore (1, 1):\n",
      "  Column Name   Dtype     Type  Fill Percentage  NaN Percentage  Bad Null Percentage\n",
      "0           *  object  str(11)            100.0             0.0                  0.0\n",
      "\n",
      "\n",
      "Metadata for metadata_EdStatsCountry-Series (613, 3):\n",
      "   Column Name   Dtype      Type  Fill Percentage  NaN Percentage  Bad Null Percentage\n",
      "0  CountryCode  object    str(3)            100.0             0.0                  0.0\n",
      "1   SeriesCode  object   str(17)            100.0             0.0                  0.0\n",
      "2  DESCRIPTION  object  str(278)            100.0             0.0                  0.0\n",
      "\n",
      "\n",
      "Metadata for metadata_EdStatsCountry (241, 31):\n",
      "                                          Column Name    Dtype       Type  Fill Percentage  NaN Percentage  Bad Null Percentage\n",
      "0                                        Country Code   object     str(3)       100.000000        0.000000                  0.0\n",
      "1                                          Short Name   object    str(46)       100.000000        0.000000                  0.0\n",
      "2                                          Table Name   object    str(46)       100.000000        0.000000                  0.0\n",
      "3                                           Long Name   object    str(73)       100.000000        0.000000                  0.0\n",
      "4                                        2-alpha code   object     str(2)        98.755187        1.244813                  0.0\n",
      "5                                       Currency Unit   object    str(42)        89.211618       10.788382                  0.0\n",
      "6                                       Special Notes   object  str(1008)        60.165975       39.834025                  0.0\n",
      "7                                              Region   object    str(26)        88.796680       11.203320                  0.0\n",
      "8                                        Income Group   object    str(20)        88.796680       11.203320                  0.0\n",
      "9                                           WB-2 code   object     str(2)        99.585062        0.414938                  0.0\n",
      "10                        National accounts base year   object   str(119)        85.062241       14.937759                  0.0\n",
      "11                   National accounts reference year  float64   float(6)        13.278008       86.721992                  0.0\n",
      "12                                SNA price valuation   object    str(36)        81.742739       18.257261                  0.0\n",
      "13                                   Lending category   object     str(5)        59.751037       40.248963                  0.0\n",
      "14                                       Other groups   object     str(9)        24.066390       75.933610                  0.0\n",
      "15                        System of National Accounts   object    str(62)        89.211618       10.788382                  0.0\n",
      "16                      Alternative conversion factor   object    str(18)        19.502075       80.497925                  0.0\n",
      "17                                    PPP survey year   object     str(7)        60.165975       39.834025                  0.0\n",
      "18                  Balance of Payments Manual in use   object    str(44)        75.103734       24.896266                  0.0\n",
      "19                     External debt Reporting status   object    str(11)        51.452282       48.547718                  0.0\n",
      "20                                    System of trade   object    str(20)        82.987552       17.012448                  0.0\n",
      "21                      Government Accounting concept   object    str(31)        66.804979       33.195021                  0.0\n",
      "22                    IMF data dissemination standard   object    str(42)        75.103734       24.896266                  0.0\n",
      "23                           Latest population census   object   str(174)        88.381743       11.618257                  0.0\n",
      "24                            Latest household survey   object   str(141)        58.506224       41.493776                  0.0\n",
      "25  Source of most recent Income and expenditure data   object    str(90)        66.390041       33.609959                  0.0\n",
      "26                        Vital registration complete   object    str(48)        46.058091       53.941909                  0.0\n",
      "27                         Latest agricultural census   object    str(36)        58.921162       41.078838                  0.0\n",
      "28                             Latest industrial data  float64   float(6)        44.398340       55.601660                  0.0\n",
      "29                                  Latest trade data  float64   float(6)        76.763485       23.236515                  0.0\n",
      "30                       Latest water withdrawal data   object    str(27)        74.273859       25.726141                  0.0\n",
      "\n",
      "\n",
      "Metadata for metadata_EdStatsData (886930, 69):\n",
      "       Column Name    Dtype       Type  Fill Percentage  NaN Percentage  Bad Null Percentage\n",
      "0     Country Name   object    str(50)       100.000000        0.000000                  0.0\n",
      "1     Country Code   object     str(3)       100.000000        0.000000                  0.0\n",
      "2   Indicator Name   object   str(164)       100.000000        0.000000                  0.0\n",
      "3   Indicator Code   object    str(30)       100.000000        0.000000                  0.0\n",
      "4             1970  float64  float(18)         8.150361       91.849639                  0.0\n",
      "..             ...      ...        ...              ...             ...                  ...\n",
      "64            2080  float64  float(10)         5.799330       94.200670                  0.0\n",
      "65            2085  float64  float(10)         5.799330       94.200670                  0.0\n",
      "66            2090  float64  float(10)         5.799330       94.200670                  0.0\n",
      "67            2095  float64  float(10)         5.799330       94.200670                  0.0\n",
      "68            2100  float64  float(10)         5.799330       94.200670                  0.0\n",
      "\n",
      "[69 rows x 6 columns]\n",
      "\n",
      "\n",
      "Metadata for metadata_EdStatsFootNote (643638, 4):\n",
      "   Column Name   Dtype       Type  Fill Percentage  NaN Percentage  Bad Null Percentage\n",
      "0  CountryCode  object     str(3)            100.0             0.0                  0.0\n",
      "1   SeriesCode  object    str(30)            100.0             0.0                  0.0\n",
      "2         Year  object     str(6)            100.0             0.0                  0.0\n",
      "3  DESCRIPTION  object  str(1132)            100.0             0.0                  0.0\n",
      "\n",
      "\n",
      "Metadata for metadata_EdStatsSeries (3665, 15):\n",
      "                            Column Name   Dtype       Type  Fill Percentage  NaN Percentage  Bad Null Percentage\n",
      "0                           Series Code  object    str(30)       100.000000        0.000000                  0.0\n",
      "1                                 Topic  object    str(92)       100.000000        0.000000                  0.0\n",
      "2                        Indicator Name  object   str(162)       100.000000        0.000000                  0.0\n",
      "3                      Short definition  object  str(2192)        58.826739       41.173261                  0.0\n",
      "4                       Long definition  object  str(2192)       100.000000        0.000000                  0.0\n",
      "5                           Periodicity  object     str(6)         2.701228       97.298772                  0.0\n",
      "6                           Base Period  object    str(26)         8.567531       91.432469                  0.0\n",
      "7                           Other notes  object    str(39)        15.061392       84.938608                  0.0\n",
      "8                    Aggregation method  object    str(16)         1.282401       98.717599                  0.0\n",
      "9            Limitations and exceptions  object  str(3275)         0.381992       99.618008                  0.0\n",
      "10                     General comments  object   str(699)         0.381992       99.618008                  0.0\n",
      "11                               Source  object   str(472)       100.000000        0.000000                  0.0\n",
      "12  Statistical concept and methodology  object   str(896)         0.627558       99.372442                  0.0\n",
      "13                Development relevance  object  str(2555)         0.081855       99.918145                  0.0\n",
      "14                 Related source links  object    str(36)         5.866303       94.133697                  0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the metadata DataFrames\n",
    "display_metadata_dfs(metadata_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e613216-b4cd-44f3-bd2d-3bd4422debdf",
   "metadata": {
    "panel-layout": {
     "height": 101.554,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Analyse des doublons et des possibles clefs de jointure via un script\n",
    "Nous allons analyser les DataFrames pour identifier les doublons et déterminer des clés primaires et/ou composites potentielles. Ensuite, nous allons tester ces clés pour vérifier leur unicité et leur adéquation en tant que clés de jointure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8e3cda3c-c9e2-4b71-adf8-7e64013e37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(dfs, ignore_fields={}, mandatory_fields={}):\n",
    "    \"\"\"\n",
    "    Checks for duplicate rows in the DataFrames and if no raw duplicates are found, checks for composite key duplicates.\n",
    "    \n",
    "    Parameters:\n",
    "    - dfs (dict): Dictionary of DataFrames to check.\n",
    "    - ignore_fields (dict): Dictionary where keys are DataFrame names and values are lists of column names to ignore.\n",
    "    - mandatory_fields (dict): Dictionary where keys are DataFrame names and values are lists of column names to use as composite keys.\n",
    "    \n",
    "    Returns:\n",
    "    - result (dict): Dictionary where keys are DataFrame names and values are tuples containing the number of raw duplicate rows and composite key duplicate rows.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    for df_name, df in dfs.items():\n",
    "        if df_name in ignore_fields:\n",
    "            # Drop the specified columns to ignore\n",
    "            df_to_check = df.drop(columns=ignore_fields[df_name], errors='ignore')\n",
    "        else:\n",
    "            df_to_check = df\n",
    "        \n",
    "        # Find raw duplicates\n",
    "        duplicate_rows = df_to_check.duplicated(keep=False)\n",
    "        num_raw_duplicates = duplicate_rows.sum()\n",
    "        \n",
    "        # Check for composite key duplicates if no raw duplicates are found\n",
    "        num_composite_key_duplicates = 0\n",
    "        if num_raw_duplicates == 0 and df_name in mandatory_fields:\n",
    "            composite_key_columns = mandatory_fields[df_name]\n",
    "            if set(composite_key_columns).issubset(df.columns):\n",
    "                composite_key_duplicates = df.duplicated(subset=composite_key_columns, keep=False)\n",
    "                num_composite_key_duplicates = composite_key_duplicates.sum()\n",
    "        \n",
    "        # Add to result\n",
    "        result[df_name] = (num_raw_duplicates, num_composite_key_duplicates)\n",
    "        \n",
    "        print(f\"DataFrame '{df_name}': {num_raw_duplicates} raw duplicate rows found, {num_composite_key_duplicates} composite key duplicate rows found\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "ignore_fields = {\n",
    "    'EdStatsCountry-Series': ['DESCRIPTION'],\n",
    "    'EdStatsCountry': ['Special Notes'],\n",
    "    'EdStatsFootNote': ['DESCRIPTION'],\n",
    "    'EdStatsSeries':['Short definition']\n",
    "}\n",
    "\n",
    "mandatory_fields = {\n",
    "    'EdStatsCountry-Series': ['CountryCode','SeriesCode'],\n",
    "    'EdStatsCountry': ['Country Code','Table Name'],\n",
    "    'EdStatsData': ['Country Code','Indicator Code'],\n",
    "    'EdStatsFootNote':['CountryCode','SeriesCode','Year'],\n",
    "    'EdStatsSeries':['Series Code','Indicator Name']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2ca368-baa3-481f-aea8-24afd991f89b",
   "metadata": {
    "panel-layout": {
     "height": 50.8214,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Resultat du script d'analyse des clefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c4bcd3e-8f5d-42f1-af88-bf5f280c3ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame '.gitignore': 0 raw duplicate rows found, 0 composite key duplicate rows found\n",
      "DataFrame 'EdStatsCountry-Series': 0 raw duplicate rows found, 0 composite key duplicate rows found\n",
      "DataFrame 'EdStatsCountry': 0 raw duplicate rows found, 0 composite key duplicate rows found\n",
      "DataFrame 'EdStatsData': 0 raw duplicate rows found, 0 composite key duplicate rows found\n",
      "DataFrame 'EdStatsFootNote': 0 raw duplicate rows found, 0 composite key duplicate rows found\n",
      "DataFrame 'EdStatsSeries': 0 raw duplicate rows found, 0 composite key duplicate rows found\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'dfs' is the dictionary of DataFrames already loaded\n",
    "duplicate_summary = check_duplicates(dfs, ignore_fields, mandatory_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a3daaa-989b-4893-a519-c5f4a6f18fd6",
   "metadata": {
    "panel-layout": {
     "height": 145.009,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "# Simplification des DataFrames en fonction de KPIs intéressants\n",
    "\n",
    "Maintenant que nous avons une vision globale de la structure et de la qualité des datasets, nous allons créer un subset de données en nous focalisant sur le besoin initial. \n",
    "\"Nous sommes une start-up de formations en ligne qui veut s'étendre à l'international et nous visons un public francophone/anglophone de 15 à 24 ans pour des formations de niveau lycée à universitaire.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c1e228-9a60-4c2c-8d28-7bc2cefe3fa7",
   "metadata": {
    "panel-layout": {
     "height": 101.554,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Étape 1 : Filtrage par exclusion des KPIs pertinents\n",
    "Nous allons adapter le script de filtrage exclure les indicateurs non-pertinents en fonction de notre public cible et nos besoins spécifiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76faaf9b-e72e-4866-b242-bb4610534992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def filter_and_save_kpis(EdStatsSeries):\n",
    "    # List of terms to ignore in the 'Topic'\n",
    "    ignore_list = ['Economic Policy', 'Education Equality', 'SABER', 'Early Childhood Education', 'Health', 'Social Protection', 'Population', 'Teachers', 'Pre-Primary', 'Primary', 'Learning Outcomes', 'Literacy']\n",
    "    ignore_pattern = '|'.join(ignore_list).replace('%', '.*')\n",
    "\n",
    "    # List of terms to ignore in the 'Indicator Name' for lower school levels\n",
    "    school_level_ignore_list = ['1st', '2nd', '3rd', '4th', '5th', '6th', 'primary', 'No Education', 'Grade']\n",
    "    school_level_ignore_pattern = '|'.join(school_level_ignore_list)\n",
    "\n",
    "    # List of terms to ignore for gender-related entries\n",
    "    gender_ignore_list = ['Female', 'Male', 'gender parity index', 'male (%)', 'toilets', 'male (number)', 'male (years)']\n",
    "    gender_ignore_pattern = '|'.join(re.escape(term) for term in gender_ignore_list)\n",
    "\n",
    "    # Define the pattern to exclude entries related to ages over 24 or under 15\n",
    "    age_pattern = r'age\\s*(?:[0-9]|1[0-4]|2[5-9]|[3-9]\\d|\\d{3,})|\\bage\\s*(?:[0-9]\\+|1[0-4]\\+|2[5-9]\\+|[3-9]\\d\\+|\\d{3,}\\+)|\\bage\\s*(?:[0-9]-\\d{2,}|1[0-4]-\\d{2,}|2[5-9]-\\d{2,}|[3-9]\\d-\\d{2,}|\\d{3,}-\\d{2,})'\n",
    "\n",
    "    # Define the pattern to keep rows with 'Learning Outcomes' if 'Indicator Name' contains 'French' or 'English'\n",
    "    language_pattern = r'French|English'\n",
    "\n",
    "    # Filter rows based on 'Topic' and 'Indicator Name', while keeping 'Learning Outcomes' with 'French' or 'English'\n",
    "    filtered_df = EdStatsSeries[\n",
    "        (~EdStatsSeries['Topic'].str.contains(ignore_pattern, regex=True) |\n",
    "         ((EdStatsSeries['Topic'] == 'Learning Outcomes') & EdStatsSeries['Indicator Name'].str.contains(language_pattern, regex=True, case=False))) &\n",
    "        ~EdStatsSeries['Indicator Name'].str.contains(age_pattern, regex=True, case=False) &\n",
    "        ~EdStatsSeries['Indicator Name'].str.contains(school_level_ignore_pattern, regex=True, case=False) &\n",
    "        ~EdStatsSeries['Indicator Name'].str.contains(gender_ignore_pattern, regex=True, case=False)\n",
    "    ][['Topic', 'Series Code', 'Indicator Name', 'Short definition']].drop_duplicates()\n",
    "\n",
    "    # Save the distinct combinations to a CSV file\n",
    "    filtered_df.to_csv(r'data/interesting_kpis.csv', index=False)\n",
    "\n",
    "    \n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "056b62c2-2de3-4be8-a009-3fcd7bf4bfc3",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the filtered DataFrame: (190, 4)\n"
     ]
    }
   ],
   "source": [
    "# call the function\n",
    "filtered_kpis = filter_and_save_kpis(EdStatsSeries)\n",
    "\n",
    "# Display the shape of the filtered DataFrame\n",
    "print(f\"Shape of the filtered DataFrame: {filtered_kpis.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018e845-ce19-4bbf-8dd1-ba73ac4bdf61",
   "metadata": {},
   "source": [
    "Fabuleux ! Nous sommes passés d'une liste de 3665 indicateurs à une liste de 190. Il serait ainsi plus facile de faire une sélection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aa71d0-173b-4966-9ec9-8095038f430f",
   "metadata": {},
   "source": [
    "## Étape 2 : Filtrage manuel en fonction d'un scénario\n",
    "\n",
    "### Pour faire une formation en ligne, les apprenants ont besoin\n",
    "- d'une connexion à internet de bonne qualité\n",
    "- d'un appareil pour y accéder (PC, smartphone, tablette, ... )\n",
    "  => Recherche d' un ou plusieurs indicateurs sur ces sujets d'infrastructure\n",
    "\n",
    "### Pour une expansion internationale facile, il faut une langue commune entre les apprenants et le centre de formation\n",
    "  => Recherche d'un indicateur sur le niveau de langue en français (ou anglais)\n",
    "\n",
    "### Il nous faut un contexte socio-économique et pouvoir se projeter avec\n",
    "- Des informations sur la démographie et son évolution sur au moins 5-10 ans dans la tranche de population cible\n",
    "- Des informations sur l'évolution du taux de poursuite d'études pour les niveaux lycée / université\n",
    "- Des informations sur l'évolution du budget pour l'éducation dans la tranche ciblée\n",
    "- Des informations sur l'évolution du PIB du pays\n",
    "  => Recherche d'un ensemble d'indicateurs pour avoir une vision socio-économique et comprendre des opportunités de marché de façon générique\n",
    "\n",
    "### Et la cerise sur le gâteau\n",
    "- Tout indicateur permettant de mieux cerner les besoins et les désirs de la génération future afin de s'assurer que les valeurs de l'entreprise sont en phase avec le futur marché\n",
    "  => 2 indicateurs max pour raconter une histoire\n",
    "\n",
    "## Catégories et Top 5 KPIs\n",
    "\n",
    "### 1. Connexion à Internet et accès à des appareils pour formation en ligne\n",
    "- **Internet users (per 100 people)** (IT.NET.USER.P2)\n",
    "- **Personal computers (per 100 people)** (IT.CMP.PCMP.P2)\n",
    "\n",
    "### 2. Niveau de langue en français ou anglais\n",
    "Pour cette catégorie, nous n'avons pas d'indicateur direct dans la liste fournie. Cependant, nous pouvons considérer les indicateurs de mobilité étudiante pour évaluer l'internationalisation des étudiants, ce qui pourrait refléter l'utilisation des langues internationales telles que l'anglais.\n",
    "\n",
    "- **Total inbound internationally mobile students, both sexes** (UIS.MS.56.T)\n",
    "- **Net flow ratio of internationally mobile students (inbound - outbound), both sexes (%)** (UIS.MENFR.56)\n",
    "- **Inbound mobility rate, both sexes (%)** (UIS.MSEP.56)\n",
    "\n",
    "### 3. Contexte socio-économique et projections\n",
    "#### 3.1. Démographie et évolution\n",
    "- **Projection: Population in thousands by highest level of educational attainment. Lower Secondary. Total** (PRJ.POP.ALL.2.MF)\n",
    "- **Projection: Population in thousands by highest level of educational attainment. Upper Secondary. Total** (PRJ.POP.ALL.3.MF)\n",
    "- **Projection: Population in thousands by highest level of educational attainment. Post Secondary. Total** (PRJ.POP.ALL.4.MF)\n",
    "\n",
    "#### 3.2. Taux de poursuite d'études\n",
    "- **Gross enrolment ratio, secondary, both sexes (%)** (SE.SEC.ENRR)\n",
    "- **Gross enrolment ratio, tertiary, both sexes (%)** (SE.TER.ENRR)\n",
    "- **Graduates from tertiary education, both sexes (number)** (SE.TER.GRAD)\n",
    "\n",
    "#### 3.3. Budget pour l'éducation\n",
    "- **Expenditure on secondary as % of government expenditure on education (%)** (SE.XPD.SECO.ZS)\n",
    "- **Expenditure on tertiary as % of government expenditure on education (%)** (SE.XPD.TERT.ZS)\n",
    "- **Government expenditure on education as % of GDP (%)** (SE.XPD.TOTL.GD.ZS)\n",
    "\n",
    "#### 3.4. PIB du pays\n",
    "Pour cette sous-catégorie, nous n'avons pas de KPI direct sur le PIB dans la liste fournie.\n",
    "Nous irons chercher cette information plus tard pour envisager plusieurs scénarii\n",
    "\n",
    "### 4. Besoins et désirs de la génération future\n",
    "- **Share of youth not in education, employment or training, total (% of youth population)** (SL.UEM.NEET.ZS)\n",
    "- **Percentage of students in secondary education enrolled in vocational programmes, both sexes (%)** (SE.SEC.ENRL.VO.ZS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a051c54-c980-48ff-a658-9c31997fd904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List of Series Codes based on selected indicators\n",
    "codeserielist = [\n",
    "    \"IT.NET.USER.P2\",  # Internet users (per 100 people)\n",
    "    \"IT.CMP.PCMP.P2\",  # Personal computers (per 100 people)\n",
    "    \"UIS.MS.56.T\",  # Total inbound internationally mobile students, both sexes\n",
    "    \"UIS.MENFR.56\",  # Net flow ratio of internationally mobile students (inbound - outbound), both sexes (%)\n",
    "    \"UIS.MSEP.56\",  # Inbound mobility rate, both sexes (%)\n",
    "    \"PRJ.POP.ALL.2.MF\",  # Projection: Population in thousands by highest level of educational attainment. Lower Secondary. Total\n",
    "    \"PRJ.POP.ALL.3.MF\",  # Projection: Population in thousands by highest level of educational attainment. Upper Secondary. Total\n",
    "    \"PRJ.POP.ALL.4.MF\",  # Projection: Population in thousands by highest level of educational attainment. Post Secondary. Total\n",
    "    \"SE.SEC.ENRR\",  # Gross enrolment ratio, secondary, both sexes (%)\n",
    "    \"SE.TER.ENRR\",  # Gross enrolment ratio, tertiary, both sexes (%)\n",
    "    \"SE.TER.GRAD\",  # Graduates from tertiary education, both sexes (number)\n",
    "    \"SE.XPD.SECO.ZS\",  # Expenditure on secondary as % of government expenditure on education (%)\n",
    "    \"SE.XPD.TERT.ZS\",  # Expenditure on tertiary as % of government expenditure on education (%)\n",
    "    \"SE.XPD.TOTL.GD.ZS\",  # Government expenditure on education as % of GDP (%)\n",
    "    \"SL.UEM.NEET.ZS\",  # Share of youth not in education, employment or training, total (% of youth population)\n",
    "    \"SE.SEC.ENRL.VO.ZS\"  # Percentage of students in secondary education enrolled in vocational programmes, both sexes (%)\n",
    "]\n",
    "\n",
    "\n",
    "# Filter the data based on the provided list of Series Codes\n",
    "reduced_kpis = filtered_kpis[filtered_kpis[\"Series Code\"].isin(codeserielist)]\n",
    "\n",
    "# Save the filtered data to a CSV file\n",
    "reduced_kpis.to_csv('data/interesting_kpis_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb2f7ad-6312-4173-b713-e00873a0a96e",
   "metadata": {
    "panel-layout": {
     "height": 84.4107,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "## Étape 3 : Application du filtrage à nos DataFrames\n",
    "Une fois les KPIs pertinents identifiés, nous allons filtrer nos DataFrames pour ne conserver que les colonnes d'intérêt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c2642-a852-40cb-96ae-cafe90361ffe",
   "metadata": {
    "panel-layout": {
     "height": 44.0804,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "### Reduction d'EdStatsSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "12eb4324-a348-403d-aabc-36b7022a05a7",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdStatsSeries_reduced(16, 16) saved to 'data/EdStatsSeries_reduced.csv'\n"
     ]
    }
   ],
   "source": [
    "# Merge the datasets on specified columns\n",
    "EdStatsSeries_reduced = pd.merge(EdStatsSeries, reduced_kpis, on=['Topic', 'Indicator Name', 'Series Code'])\n",
    "\n",
    "# Save the reduced DataFrame to a CSV file\n",
    "EdStatsSeries_reduced.to_csv('data/EdStatsSeries_reduced.csv', index=False)\n",
    "\n",
    "# Print the shape of the DataFrame and confirm save\n",
    "print(f\"EdStatsSeries_reduced{EdStatsSeries_reduced.shape} saved to 'data/EdStatsSeries_reduced.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151f84d",
   "metadata": {},
   "source": [
    "### Reduction d'EdStatsCountry\n",
    "\n",
    "EdStatsCountry_reduced permet d'améliorer la visibilité en se focalisant sur les colonnes nécéssaires et suffisantes à notre étude.\n",
    "De plus, il faut ajouter un tag pour distinguer les groupes et les pays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5e751d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define important columns\n",
    "important_columns = [\n",
    "    'Country Code', 'Short Name', 'Table Name', 'Long Name',\n",
    "    'Region', 'Income Group'\n",
    "]\n",
    "\n",
    "# Reduce the DataFrame to only important columns\n",
    "EdStatsCountry_reduced = EdStatsCountry[important_columns].copy()\n",
    "\n",
    "# Add a 'Category' column to indicate if each entry is a 'Country' or 'Group'\n",
    "def determine_category(row):\n",
    "    if 'income' in str(row['Income Group']).lower():\n",
    "        return 'Country'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Use .loc to modify the DataFrame\n",
    "EdStatsCountry_reduced.loc[:, 'Category'] = EdStatsCountry_reduced.apply(determine_category, axis=1)\n",
    "\n",
    "# Save the reduced DataFrame with the category\n",
    "EdStatsCountry_reduced.to_csv('data/EdStatsCountry_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8afd9e9-d265-4f20-b252-466711dd76e4",
   "metadata": {
    "panel-layout": {
     "height": 96.4911,
     "visible": true,
     "width": 100
    }
   },
   "source": [
    "### Reduction d'EdStatsData et d'EdStatsFootNote\n",
    "- `EdStatsData_reduced` : Contient uniquement les `Indicator Name` présents dans `EdStatsSeries_reduced`.\n",
    "- `EdStatsFootNote_reduced` : Contient uniquement les `Series Code` présents dans `EdStatsSeries_reduced`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f7f25ad2-be0b-4032-b687-f99ba158000d",
   "metadata": {
    "panel-layout": {
     "height": 0,
     "visible": true,
     "width": 100
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EdStatsData_reduced (3424, 22) saved to 'data/EdStatsData_reduced.csv'\n",
      "EdStatsFootNote_reduced (21323, 4) saved to 'data/EdStatsFootNote_reduced.csv'\n"
     ]
    }
   ],
   "source": [
    "# Filter the countries\n",
    "country_codes = EdStatsCountry_reduced[EdStatsCountry_reduced['Category'] == 'Country']['Country Code']\n",
    "\n",
    "# Reduction of EdStatsData\n",
    "EdStatsData_reduced = EdStatsData[EdStatsData['Indicator Code'].isin(EdStatsSeries_reduced['Series Code'])]\n",
    "EdStatsData_reduced = EdStatsData_reduced[EdStatsData_reduced['Country Code'].isin(country_codes)]\n",
    "\n",
    "# Identify the necessary columns and year columns for EdStatsSeries_reduced\n",
    "necessary_columns = ['Indicator Name', 'Indicator Code', 'Country Name', 'Country Code']\n",
    "year_columns = ['2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012','2013','2014','2015', '2016', '2017', '2020', '2025', '2030', '2035']\n",
    "\n",
    "# Filter the DataFrame to retain only those columns\n",
    "available_columns = [col for col in necessary_columns + year_columns if col in EdStatsData_reduced.columns]\n",
    "EdStatsData_reduced = EdStatsData_reduced[available_columns]\n",
    "\n",
    "# Reduction of EdStatsFootNote\n",
    "EdStatsFootNote_reduced = EdStatsFootNote[EdStatsFootNote['SeriesCode'].isin(EdStatsSeries_reduced['Series Code'])]\n",
    "\n",
    "# Save the reduced DataFrames\n",
    "EdStatsData_reduced.to_csv('data/EdStatsData_reduced.csv', index=False)\n",
    "EdStatsFootNote_reduced.to_csv('data/EdStatsFootNote_reduced.csv', index=False)\n",
    "\n",
    "# Print the shape of the reduced DataFrames\n",
    "print(f\"EdStatsData_reduced {EdStatsData_reduced.shape} saved to 'data/EdStatsData_reduced.csv'\")\n",
    "print(f\"EdStatsFootNote_reduced {EdStatsFootNote_reduced.shape} saved to 'data/EdStatsFootNote_reduced.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1739a64e",
   "metadata": {},
   "source": [
    "### Analyse graphique\n",
    "\n",
    "> **Remarque :**\n",
    "> - En raison de la limitation du projet, qui est de créer un code simple et de regrouper toutes les explications dans un seul notebook Jupyter, toutes les fonctions sont regroupées dans ce même notebook.\n",
    "> - Après avoir expérimenté avec divers outils de visualisation tels que Seaborn et Matplotlib, j'ai constaté qu'il était possible de simplifier l'agrégation des données en prenant la dernière valeur disponible pour chaque pays et chaque KPI.\n",
    "> - L'approche graphique se concentrera principalement sur des heatmaps, pour changer des habitudes de visualisation.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Objectif de l'analyse\n",
    "L'objectif de cette analyse graphique est de fournir une vue d'ensemble visuelle des indicateurs clés de performance (KPI) par pays. Cette approche permet d'identifier rapidement les tendances et les anomalies à travers différents pays et indicateurs.\n",
    "\n",
    "#### 2. Méthodologie\n",
    "- **Agrégation des données** : Pour chaque pays et chaque KPI, nous utilisons la dernière valeur disponible afin de garantir une analyse pertinente et à jour.\n",
    "- **Heatmaps** : Les heatmaps sont utilisées pour visualiser les données de manière intuitive et identifier les points forts et les points faibles par pays et par indicateur.\n",
    "\n",
    "#### 3. Bibliothèques utilisées\n",
    "- **Pandas** : Pour la manipulation et l'analyse des données.\n",
    "- **Seaborn** et **Matplotlib** : Pour la visualisation des données.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Implémentation des fonctions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "172a2aa1-5aac-4c84-9ac3-475e803deada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract the latest values for each indicator\n",
    "def extract_latest_values(EdStatsData_reduced, EdStatsSeries_reduced, year_columns):\n",
    "    unique_indicators = EdStatsSeries_reduced['Series Code'].unique()\n",
    "    indicators_no_data = []\n",
    "    combined_latest_values = pd.DataFrame(index=EdStatsData_reduced['Country Code'].unique())\n",
    "\n",
    "    for indicator_code in unique_indicators:\n",
    "        df_indicator = EdStatsData_reduced[EdStatsData_reduced['Indicator Code'] == indicator_code]\n",
    "\n",
    "        if df_indicator[year_columns].isnull().all().all():\n",
    "            indicators_no_data.append(indicator_code)\n",
    "            continue\n",
    "\n",
    "        heatmap_data = df_indicator.pivot_table(\n",
    "            values=year_columns,\n",
    "            index=['Country Code'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "\n",
    "        present_year_columns = [col for col in year_columns if col in heatmap_data.columns]\n",
    "\n",
    "        if not present_year_columns:\n",
    "            indicators_no_data.append(indicator_code)\n",
    "            continue\n",
    "\n",
    "        # Extract the latest values for the current indicator\n",
    "        latest_values = heatmap_data.apply(lambda row: row.dropna().values[-1] if not row.dropna().empty else None, axis=1)\n",
    "        combined_latest_values[indicator_code] = latest_values\n",
    "\n",
    "    return combined_latest_values, indicators_no_data\n",
    "\n",
    "# Function to calculate statistics and store in a DataFrame\n",
    "def calculate_statistics(combined_latest_values, EdStatsSeries_reduced):\n",
    "    statistics = []\n",
    "\n",
    "    for indicator_code in combined_latest_values.columns:\n",
    "        values = combined_latest_values[indicator_code].dropna()\n",
    "\n",
    "        if values.empty:\n",
    "            continue\n",
    "\n",
    "        mean_val = values.mean()\n",
    "        median_val = values.median()\n",
    "        std_val = values.std()\n",
    "        indicator_name = EdStatsSeries_reduced[EdStatsSeries_reduced['Series Code'] == indicator_code]['Indicator Name'].values[0]\n",
    "\n",
    "        statistics.append({\n",
    "            'Indicator Name': indicator_name,\n",
    "            'Indicator Code': indicator_code,\n",
    "            'Mean': mean_val,\n",
    "            'Median': median_val,\n",
    "            'Std Dev': std_val\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(statistics)\n",
    "\n",
    "# Function to select top 20 countries for each income group based on the latest values of an indicator\n",
    "def select_top_countries(EdStatsCountry_reduced, combined_latest_values, statistics_df, top_n=20):\n",
    "    top_countries_dict = {}\n",
    "    enriched_statistics = statistics_df.copy()\n",
    "    income_groups = EdStatsCountry_reduced['Income Group'].unique()\n",
    "\n",
    "    for index, row in statistics_df.iterrows():\n",
    "        indicator_code = row['Indicator Code']\n",
    "        top_countries_dict[indicator_code] = {}\n",
    "        for income_group in income_groups:\n",
    "            countries_in_group = EdStatsCountry_reduced[EdStatsCountry_reduced['Income Group'] == income_group]['Country Code']\n",
    "            countries_in_group = countries_in_group[countries_in_group.isin(combined_latest_values.index)]\n",
    "            \n",
    "            latest_values_in_group = combined_latest_values.loc[countries_in_group].dropna(how='all')\n",
    "            if not latest_values_in_group.empty:\n",
    "                top_countries_in_group = latest_values_in_group[indicator_code].nlargest(top_n).index.tolist()\n",
    "                top_countries_dict[indicator_code][income_group] = top_countries_in_group\n",
    "                \n",
    "                # Create a list to hold new rows\n",
    "                new_rows = []\n",
    "                for position, country_code in enumerate(top_countries_in_group, start=1):\n",
    "                    new_rows.append({\n",
    "                        'Indicator Name': row['Indicator Name'],\n",
    "                        'Indicator Code': indicator_code,\n",
    "                        'Income Group': income_group,\n",
    "                        'Country Code': country_code,\n",
    "                        'Country Rank': position,\n",
    "                        'Value': latest_values_in_group.loc[country_code]\n",
    "                    })\n",
    "                \n",
    "                # Convert the list of new rows to a DataFrame and concatenate it to enriched_statistics\n",
    "                new_rows_df = pd.DataFrame.from_records(new_rows)\n",
    "                enriched_statistics = pd.concat([enriched_statistics, new_rows_df], ignore_index=True)\n",
    "\n",
    "    return top_countries_dict, enriched_statistics\n",
    "\n",
    "# Function to draw histograms from statistics DataFrame\n",
    "def draw_histograms_from_statistics(statistics_df, combined_latest_values):\n",
    "    for index, row in statistics_df.iterrows():\n",
    "        indicator_code = row['Indicator Code']\n",
    "        indicator_name = row['Indicator Name']\n",
    "        mean_val = row['Mean']\n",
    "        median_val = row['Median']\n",
    "        \n",
    "        values = combined_latest_values[indicator_code].dropna()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(values, kde=True, bins=20, color='blue', alpha=0.6)\n",
    "        plt.axvline(mean_val, color='r', linestyle='--', label=f'Mean: {mean_val:.2f}')\n",
    "        plt.axvline(median_val, color='g', linestyle='-', label=f'Median: {median_val:.2f}')\n",
    "        plt.title(f'Histogram of {indicator_name} (Latest Values)')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        file_name = f\"histogram_{indicator_code}.png\"\n",
    "        plt.savefig(f'data/graph/{file_name}')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f475f82b-af6f-49f1-b40a-483cd6884717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des dernières valeurs\n",
    "combined_latest_values, indicators_no_data = extract_latest_values(EdStatsData_reduced, EdStatsSeries_reduced, year_columns)\n",
    "\n",
    "# Calcul des statistiques et stockage dans un DataFrame\n",
    "statistics_df = calculate_statistics(combined_latest_values, EdStatsSeries_reduced)\n",
    "statistics_df.to_csv('data/graph/statistics.csv', index=False)\n",
    "\n",
    "# Sélection des 20 meilleurs pays pour chaque groupe de revenus et enrichissement du DataFrame des statistiques\n",
    "top_countries_dict, enriched_statistics_df = select_top_countries(EdStatsCountry_reduced, combined_latest_values, statistics_df, top_n=20)\n",
    "enriched_statistics_df.to_csv('data/graph/enriched_statistics.csv', index=False)\n",
    "\n",
    "# Dessiner les histogrammes à partir des statistiques calculées\n",
    "draw_histograms_from_statistics(statistics_df, combined_latest_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "60602802",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = EdStatsData.loc[\n",
    "    (EdStatsData['Country Code'] == 'CAN') & \n",
    "    (EdStatsData['Indicator Code'].isin(codeserielist))\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c1c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate individual heatmaps using extracted latest values\n",
    "def generate_individual_heatmaps(EdStatsData_reduced, EdStatsSeries_reduced, year_columns, combined_latest_values, top_countries_dict):\n",
    "    unique_indicators = EdStatsSeries_reduced['Series Code'].unique()\n",
    "\n",
    "    for indicator_code in unique_indicators:\n",
    "        df_indicator = EdStatsData_reduced[EdStatsData_reduced['Indicator Code'] == indicator_code]\n",
    "\n",
    "        if df_indicator[year_columns].isnull().all().all():\n",
    "            continue\n",
    "\n",
    "        heatmap_data = df_indicator.pivot_table(\n",
    "            values=year_columns,\n",
    "            index=['Country Code'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "\n",
    "        present_year_columns = [col for col in year_columns if col in heatmap_data.columns]\n",
    "\n",
    "        if not present_year_columns:\n",
    "            continue\n",
    "\n",
    "        # Identify the latest year with data for sorting\n",
    "        latest_year_with_data = heatmap_data[present_year_columns].apply(lambda row: row.last_valid_index(), axis=1).max()\n",
    "        if latest_year_with_data:\n",
    "            # Sort the heatmap data by the latest year with data in descending order\n",
    "            heatmap_data.sort_values(by=latest_year_with_data, ascending=False, inplace=True)\n",
    "        else:\n",
    "            # If no latest year with data is found, sort by the last present year column in descending order\n",
    "            heatmap_data.sort_values(by=present_year_columns[-1], ascending=False, inplace=True)\n",
    "\n",
    "        indicator_name = EdStatsSeries_reduced[EdStatsSeries_reduced['Series Code'] == indicator_code]['Indicator Name'].values[0]\n",
    "\n",
    "        fig, axes = plt.subplots(1, len(top_countries_dict[indicator_code]), figsize=(30, 10))\n",
    "        fig.suptitle(f'Heatmap of {indicator_name} by Country', fontsize=16)\n",
    "\n",
    "        for i, (income_group, top_countries) in enumerate(top_countries_dict[indicator_code].items()):\n",
    "            sns.heatmap(\n",
    "                heatmap_data.loc[top_countries],\n",
    "                cmap='RdYlGn',\n",
    "                cbar_kws={'label': 'Value'},\n",
    "                linewidths=0.5,\n",
    "                mask=heatmap_data.isnull(),  # Mask NaN values to show them as blank\n",
    "                yticklabels=True,\n",
    "                ax=axes[i]\n",
    "            )\n",
    "            axes[i].set_title(f'{income_group}', fontsize=14)\n",
    "            axes[i].set_xlabel('Year', fontsize=12)\n",
    "            axes[i].set_ylabel('Country', fontsize=12)\n",
    "            axes[i].tick_params(axis='y', labelsize=10, rotation=0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        file_name = f\"data/graph/heatmap_{indicator_code}.png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b05b6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des heatmaps individuelles\n",
    "generate_individual_heatmaps(EdStatsData_reduced, EdStatsSeries_reduced, year_columns, combined_latest_values, top_countries_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5494c98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate individual heatmaps using extracted latest values\n",
    "def generate_individual_heatmaps(EdStatsData_reduced, EdStatsSeries_reduced, year_columns, combined_latest_values, top_countries_dict):\n",
    "    unique_indicators = EdStatsSeries_reduced['Series Code'].unique()\n",
    "\n",
    "    for indicator_code in unique_indicators:\n",
    "        df_indicator = EdStatsData_reduced[EdStatsData_reduced['Indicator Code'] == indicator_code]\n",
    "\n",
    "        if df_indicator[year_columns].isnull().all().all():\n",
    "            continue\n",
    "\n",
    "        heatmap_data = df_indicator.pivot_table(\n",
    "            values=year_columns,\n",
    "            index=['Country Code'],\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "\n",
    "        present_year_columns = [col for col in year_columns if col in heatmap_data.columns]\n",
    "\n",
    "        if not present_year_columns:\n",
    "            continue\n",
    "\n",
    "        # Identify the latest year with data for sorting\n",
    "        latest_year_with_data = heatmap_data[present_year_columns].apply(lambda row: row.last_valid_index(), axis=1).max()\n",
    "        if latest_year_with_data:\n",
    "            # Sort the heatmap data by the latest year with data in descending order\n",
    "            heatmap_data.sort_values(by=latest_year_with_data, ascending=False, inplace=True)\n",
    "        else:\n",
    "            # If no latest year with data is found, sort by the last present year column in descending order\n",
    "            heatmap_data.sort_values(by=present_year_columns[-1], ascending=False, inplace=True)\n",
    "\n",
    "        indicator_name = EdStatsSeries_reduced[EdStatsSeries_reduced['Series Code'] == indicator_code]['Indicator Name'].values[0]\n",
    "\n",
    "        fig, axes = plt.subplots(1, len(top_countries_dict[indicator_code]), figsize=(30, 10))\n",
    "        fig.suptitle(f'Heatmap of {indicator_name} by Country', fontsize=16)\n",
    "\n",
    "        for i, (income_group, top_countries) in enumerate(top_countries_dict[indicator_code].items()):\n",
    "            # Ensure top_countries are in heatmap_data\n",
    "            valid_countries = [country for country in top_countries if country in heatmap_data.index]\n",
    "            \n",
    "            if not valid_countries:\n",
    "                continue\n",
    "            \n",
    "            sns.heatmap(\n",
    "                heatmap_data.loc[valid_countries],\n",
    "                cmap='RdYlGn',\n",
    "                cbar_kws={'label': 'Value'},\n",
    "                linewidths=0.5,\n",
    "                mask=heatmap_data.isnull(),  # Mask NaN values to show them as blank\n",
    "                yticklabels=True,\n",
    "                ax=axes[i]\n",
    "            )\n",
    "            axes[i].set_title(f'{income_group}', fontsize=14)\n",
    "            axes[i].set_xlabel('Year', fontsize=12)\n",
    "            axes[i].set_ylabel('Country', fontsize=12)\n",
    "            axes[i].tick_params(axis='y', labelsize=10, rotation=0)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        file_name = f\"data/graph/heatmap_{indicator_code}.png\"\n",
    "        plt.savefig(file_name)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c7db17-4e37-4a8f-a06b-1a98d9b47e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate scores based on a priority list\n",
    "def calculate_scores(combined_data, priority_list):\n",
    "    score = combined_data[priority_list].sum(axis=1)\n",
    "    combined_data['Score'] = score\n",
    "    combined_data.sort_values('Score', ascending=False, inplace=True)\n",
    "    return combined_data\n",
    "\n",
    "\n",
    "\n",
    "# Function to create a styled table with colored cells based on values\n",
    "def create_styled_table(combined_data):\n",
    "    combined_data = combined_data.apply(pd.to_numeric, errors='coerce')\n",
    "    combined_data.sort_index(inplace=True)\n",
    "    \n",
    "    def color_cells(val):\n",
    "        if pd.isnull(val):\n",
    "            return f'background-color: rgba(255, 255, 128, .5)'\n",
    "        color = sns.color_palette(\"RdYlGn\", as_cmap=True)(val / combined_data.max().max())\n",
    "        return f'background-color: rgba({color[0]*255}, {color[1]*0}, {color[2]*255}, 0.7)'\n",
    "\n",
    "    styled_table = combined_data.style.map(lambda x: '').background_gradient(cmap='RdYlGn').format(lambda x: '' if pd.isnull(x) else '')\n",
    "\n",
    "    # Modify headers to include slashes\n",
    "    styled_table.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('text-align', 'center')]},\n",
    "        {'selector': 'th.col_heading', 'props': [('white-space', 'nowrap'), ('border-bottom', '1px solid black')]}\n",
    "    ])\n",
    "    styled_table.set_table_attributes('style=\"border-collapse:collapse; border:1px solid black\"')\n",
    "    styled_table.set_properties(**{'text-align': 'center'})\n",
    "\n",
    "    # Save the styled table to an HTML file\n",
    "    styled_table.to_html('data/graph/consolidated_latest_value_table.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f44a0-dad4-467b-b23b-cbca1f7056b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define priority list for KPIs\n",
    "# priority_list = ['IT.CMP.PCMP.P2', 'IT.NET.USER.P2', 'SE.SEC.ENRL.VO.ZS']\n",
    "\n",
    "# Calculate scores and sort combined data\n",
    "# combined_latest_values = calculate_scores(combined_latest_values, priority_list)\n",
    "\n",
    "\n",
    "\n",
    "# Create the styled table\n",
    "create_styled_table(combined_latest_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d500b-1bbd-44e3-afc9-532a6e4b8453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "panel-cell-order": [
   "1c0d9927-7ee4-44a0-8e1e-e582121efd41",
   "537600a9-d320-4272-876d-c1a462e44bb7",
   "50193f1b-e777-43fc-ac6d-2cde6de2243f",
   "c4378a17-1da4-4d4e-86b9-969d71e8e3da",
   "e873ebfe-0ba5-4287-a417-e3fdffad1ca1",
   "208d0847-46a4-4b22-8bfe-b550747b7f1a",
   "5e29f58f-bce7-4bd8-8bec-f4a3bc07b55a",
   "3ae46763-fc45-4910-bf93-9d04dd20726b",
   "4e613216-b4cd-44f3-bd2d-3bd4422debdf",
   "3f2ca368-baa3-481f-aea8-24afd991f89b",
   "90a3daaa-989b-4893-a519-c5f4a6f18fd6",
   "a8c1e228-9a60-4c2c-8d28-7bc2cefe3fa7",
   "9fb2f7ad-6312-4173-b713-e00873a0a96e",
   "056b62c2-2de3-4be8-a009-3fcd7bf4bfc3",
   "a35c2642-a852-40cb-96ae-cafe90361ffe",
   "12eb4324-a348-403d-aabc-36b7022a05a7",
   "d8afd9e9-d265-4f20-b252-466711dd76e4",
   "f7f25ad2-be0b-4032-b687-f99ba158000d"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
